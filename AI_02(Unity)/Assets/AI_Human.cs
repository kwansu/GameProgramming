using System;
using System.Collections.Generic;
using UnityEngine;

public class AI_Human : MonoBehaviour
{
    Object_Human selfBody;

    // 살아가는 이유/원인/원동력에 얼마나 영향을 주는지 나타내는 수치들.

    // 사건의 강렬함/중요도를 나타낸다.
    float ga;
    // 행동에 따른 결과등에 포상/보상/행복감등을 나타낸다.
    float na;
    // 반대로 스트레스/벌점/위험/기분나쁨등을 나타낸다.
    float da;
    // 흥분/고양 등의 상태를 나타낸다.
    float ra;

    // 인지 중인 물체들 임시 데이터
    List<FieldObject> enterFieldObjects;
    List<FieldObject> exitFieldObjects;
    List<FieldEnvironment> enterFieldEnvironments;
    List<FieldEnvironment> exitFieldEnvironments;

    LinkedList<FieldObject> recognizedFieldObjects;
    LinkedList<FieldEnvironment> recognizedFieldEnvironments;

    LinkedList<YTime> timeline;

    // 자신 스스로에 대한 염소/상념들
    LinkedList<Ye_SelfState> selfStates;
    float hugerPoint;
    SelfStateData expectedData;

    // memory
    List<Yeomso_Event> events;

    Dictionary<Gaenyeom.GaenyeomTypeNumber, Gaenyeom> gaenyeoms;

    private void Start()
    {
        selfBody = GetComponent<Object_Human>();

        if (selfBody == null)
        {
            Debug.LogError(1);
        }
    }

    private void Update()
    {
        /// 세상에 대한 기본적인 지식(세계관)이 있고, 이제 자유가 되었다.
        /// '무엇을' '어떻게' '왜' 해야하는가?
        /// 매 순간 들어오는 시야내의 필드 정보, 그리고 현재 나의 상태(배고픔/체력)와 소지한 물품들.
        /// 캐릭터는 처음으로 어떤 '행동'을 할까?
        /// 아니, 좀더 구체적인 상황을 만들어야 생각의 과정과 행동을 정할 수 있다.
        /// 현재 세상에는 크게 3가지 국가 A, B, C로 나누어져 있다.
        /// 뭐 사이는 그다지 좋지 않은지 툭하면 싸우지만, 현재는 균형이 맞쳐져있다고 가정한다.
        /// 캐릭터는 A국가의 마을 평범한 시민으로 태어나, 성인까지 마을의 일(광산/농사)을 도우며 살아왔다.
        /// A가 아는 거라고는 근처의 마을 하나와 큰 도시 하나, 그리고 그 주변 지리 밖에 모른다.
        /// 캐릭터가 아는 선에서 A왕국은 왕족, 귀족, 평민으로 계급이 나뉜다.
        /// 왕족은 혈통으로 현재 왕과 왕비 아들 둘 그리고 딸 하나를 알고 있다.
        /// 귀족도 혈통제지만, 왕이 큰 일을 한 평민을 귀족으로 임명할 수 있다고 알고있다.
        /// 현재 알고 있는 귀족은 근처의 큰 도시와 자신의 마을과 근처 마을의 영주 뿐이다.

        /// 생각해 보니깐 큰 문제가 있다. 바로 세계관과 가치관 구성이다.
        /// 게임 세상의 법칙들 오브젝트, 필드, 위치, 필드오브젝트, 거주지, 사람, 그룹, 물건, 소지품, 장비품,
        /// 시야, 보다, 체력, 속도, 배고픔, 무게, 공격력, 방어력, 이동, 작업, 전투방법, 등
        /// 이런 게임 시스템에서 제공하고 정보,능력,행동들을 기본적인 개념으로 넣을 수 있다고 치자.
        /// 하지만, 왕이라든지 귀족이라든지 이런것은 사람이 만든 규칙이자 구분이다.
        /// 물론 저런 것도 충분히 개념이 될 수 있고, 되어야 하기 때문에 현재의 개념이라는 것을 구성한 것이다.
        /// 문제는 저런 개념을 일일이 다 만드는 것도 문제이지만, 설사 모든 개념을 다 만들어 놓아도 문제이다.
        /// 생각해보자, 왕/귀족/평민이라는 구분을 만들어 놓았다.
        /// 하지만, 평범한 시민 한명이 왕과 귀족이 시키는대로 해야하는 이유가 뭔가?
        /// 현실에서도 당연히 그런 이유는 존재하지 않았지만, 인류의 발전에서 상황과 환경이 자연스럽게
        /// 그런 구조를 만든것이다. 평민으로 태어난 사람은 평범한 인간의 본능만을 가지고 태어나서
        /// 크면서 주위로부터 사회의 구조라는 것을 배우고 경험하게 된다.
        /// 그것이 평민이 왕과 귀족의 말을 따르면서 함부로 못하고 쉽게 반항하지 못하는 것이다.
        /// 물론 그런 사회구조도 하루 아침에 생겨난 것이 아니다, 인간의 본능과 환경, 그리고 시간에 따라
        /// 천천히 형성된 것이다.
        /// 여기서 만들어 내야하는 것은 단순히 세상의 기본 법칙을 아는게 다가 아니라, 인간 사회의 구조도
        /// 만들어 내야 한다는 것이다.

        /// 사회구조... 이것은 법칙이 정해진 세상의 인간들이 그 환경과 본능에 따라 살아오면서 자연스럽게
        /// 형성된 것이다. 이걸 그냥 구현 하는게 가능할까?
        /// 그렇게 따지면 인간의 본능조차도 법칙이 정해진 세상과 환경에서 적응하면서 오랜 시간에 걸쳐
        /// 형성된 것이다. 하지만 나는 지금 본능을 만들려고 하고있다.
        /// 그럼 본능 쉬운가? 배고프면 먹고, 안전한 잠자리를 찾고, 적의로부터의 위협과 사냥등을 위해 무리를
        /// 만들고, 살기위해서 온갖 일과 노동을 하고, 번식을 위해서 이성을 원하게 되고, 더 나아가 좋은 후손을
        /// 위해서 더 좋은 이성을 차지하려고 하고 경쟁하고, 나중을 위해서 식량을 보존하고, 농사하며,
        /// 사냥과 적으로부터 이기기위해 더 좋은 무기를 찾고 만들기도 하는 모든 것.
        /// 거기에 더해 생존과 경쟁에서 이기기 위해 무리, 부족, 나라를 만드는 이 모든 것이 본능이다.
        /// 수 많은 시간동안 적응과 경험을 통해서 쌓이고 발전한 것들이다.
        /// 이런 것들을 어떻게 만들 것인가?

        /// 본능을 형성하는 것부터가 시작이다. 오랜 시간을 통해 환경에 적응하고 생존하고 경쟁하며 경험하며,
        /// 쌍힌 본능이라는 것이다.
        /// 지금부터는 가장 원초적 본능을 만들어야 한다.
        /// '생존'과 '적응' 그리고 '번식'
        /// 그리고 저것들이 가능한 기본 모델들로 부터 환경을 조절하며 경험을 쌓아가서
        /// 내가 원하는 개념, 즉 내가 생각하고 있는 가치관과 세계관을 가진 사람이라는 것의 기본을 만들어야한다.
        /// 시작은 세상의 법칙을 알고 있는 사람이다.
        /// 당연히 그 사람은 시간이 지나 굶어 죽을 것이다.
        /// 그럼 생존하고 적응해서 살아가는 사람을 만들면 되는 것이다.

        /// '호르몬'과 '항상성' 그리고 '보상/포상'(도마핀등) 으로 생각을 창발해보자.
        /// 원시 생물 하나가 있다고 가정하자.
        /// 이 생물이 살아가는 이유는 '생존' 그리고 그걸 위해서는 오직 '만복도'가 떨어지지 않게
        /// '먹기'만을 하면 해결 된다고 가정하자.
        /// 생물은 시간에 따라 만복도가 떨어지게 될것이고, 그 때마다 머릿속에는 '배고픔'이라는
        /// 개념이 떠오르거나 또는 '먹기'라는 개념이 떠오를 것이다.
        /// 여기서 '배고픔'이라는 개념이 떠올라서 거기에 대비로 '먹기'가 떠오르는 건지, 필요한건지는 모르겠다.
        /// 해결책은 '먹기' 뿐이므로, 일단 '배고픔->먹기'라는 개념/생각이 떠오른다고 치자.
        /// 여기서 두가지 경우를 생각해 봐야한다.
        /// 하나는 '먹은 경험/기억'이 있는 경우와 다른 하나는 '경험/기억' 전혀 없는 경우.
        /// 경험/기억이 있을 경우 그 기억은 강렬할수록 즉 '보상/포상'이 클수록, 최근 기억일수록
        /// 더 쉽게 생각날 것이다.
        /// 즉 '배고픔->먹기'라는 개념/생각에 강렬한 순으로 기억/경험들이 연결되어 있다는 것이다.
        /// 그리고 거기에 계속해서 들어오는 관찰정보에서 물체가 들어 온다면 그게 경험/기억상 먹을것인지
        /// 알것이고, 먹을수 있는 것이라면 현재의 '배고픔->먹기'의 해결책으로 그것을 먹으려고 할 것이다.
        /// 정리하자면 경험/기억이 있을 경우, 우선적으로 관찰정보에 '물체'에 대한 판단/평가가 이루어지고,
        /// 그것이 만약 '먹을 수 있는 것'이라면 '먹다'라는 개념에 연결될 것이다.
        /// 거기서 만복도가 떨어져서 '배고픔->먹기'라는 개념/생각이 떠오르면 우선적으로 아까 연결된
        /// 물체가 가장 먼저 떠오르고 그것을 먹을 것이지만, 관찰/인지 된 물체에서 먹을것이 없어서 연결된
        /// '먹을 것'이 없다면 '먹다'라는 개념/생각에 연결된 강렬한 생각 순으로 기억/경험을 탐색하게 될 것이다.
        /// '기억/경험'이 없을 경우.
        /// 관찰 정보가 들어왔을 때, 그게 '먹을 것'인지 판단/평가 할 수 있을까?
        /// 본능적으로 알지 않을까? 생물은 기본적으로 자신이 먹을 수 있는것을 어느정도 알고있다.
        /// 그게 아니더라도 입에 넣을 수 있는 크기의 처음보는 것이라면, '먹음직'해 보이는 것이라면 일단
        /// 먹어보고 '맛'으로 판단해서 삼키지 않을까? 그게 그 물체에 대한 최초의 '경험/기억'이 될 것이고.
        /// 그래, 본능적으로 물건에 대한 판단을 한다고 치자. 그럼 시야의 관찰 정보에 전혀 '먹을 만한게'
        /// 없을 경우는 어떻게 할까? 이전에 어디서 먹을 것을 구한 기억도 경험도 없는데, 어떻게 먹을 것을
        /// 찾을까? 먹을 것을 찾기위해 어디로, 어떻게, 어떤 근거로 움직이게 되는 것일까?
        /// ...이것도 본능의 영역이겠지. 본능이라고 퉁치면 다 해결돼.
        /// 본능이라는 것은 결국 먼 조상부터의 '경험'하고 '적응'하고 '학습'한 것이 유전된 것이다.
        /// 최초의 생물들은 여기 저기 아무렇게나 랜덤이동 했을 것이다. 하지만, '먹을 것'이 있는 곳으로
        /// 이동한 개체들만 살았을 것이고, 그 개체들은 자신들이 이동한 곳의 특징을 기억하고 하였고,
        /// 그게 반복되어 본능적으로 특정 장소로 이동하면 '먹을 것'이 있다는 것을 알게 된 것이다.
        /// 마찬가지로 먹을 것도 이것저것 다 먹어보면서 살아남은 놈들이 본능적으로 먹을것을 알게 된 거겠지.
        /// 그럼 여기서 내가 해야 할 일은 그 본능이라는 것을 만들어야 한다.
        /// 시뮬레이션을 돌려서 어떤식으로 구축되는지 보고, 그걸 따라서 새로운 본능을 직접 만들 수 있지않을까?
        /// 수 많은 시간과 적응, 돌연변이등의 요소로 희박하게 살아남은 진화라는것을 구현하자고?
        /// 나는 단순히 그 '결과'로 구현된 '본능'만을 원하지 어떤 과정인지 궁금하지 않다.

        /// 도대체 그 본능이라는 것을 어떤 형태라서, 사고/생각에 영향을 주는가?
        /// 본능이라는 것도 결국 '경험/기억'과 별로 다를 것 없지 않나?
        /// 태어날 때부터 가지고 있는 지워지지 않는 기억/경험 이라고 보면 되지 않을까?
        /// 정확하게는 경험/기억과 다르겠지만 일단 형태나 사용하는 방식을 비슷할 것이다.
        /// 즉, 경험/기억의 형태로 만들어서 알맞은 개념에 연결되면 되는 것이다.
        /// 여기서 이제 문제는 자세히 생각해본적 없던 '경험/기억'의 형태이다.

        /// 경험과 기억.
        /// 간단하게 음식를 구한 경험을 기억한다고 해보자.
        /// 음식를 발견한 순간, 구한 순간을 기억할 것 이라고 생각된다.
        /// 그 순간의 상황과 환경을 그대로 저장하면 그것이 기억 아닐까?
        /// 그러면 여기서 '상황'과 '환경'은 어떤 형태로 저장하며, 어디에 어떤 식으로 연결해서 저장해야
        /// 나중에 이 기억을 다시 사용할 수 있을까?
        /// 일단 이 경험/기억 이라는 것은 필요한 순간에 다시 떠올려서 사용하기 위한 것이다.
        /// 즉, '필요한 순간'과 다시 '떠올리는 것'을 상정하고 구현해야하는 것이다.
        /// 음식를 발견한 순간/구한 순간, 이게 '필요한 순간'은 결국 음식다.
        /// 즉, '음식'라는 생각/개념에 저 순간의 기억들을 연결해야 한다.
        /// 떠올리는 거야 '음식'에 연결되어있는 기억/경험들에서 정렬된 순서로 찾으면 되는것이다.
        /// 그럼 연결된 기억/경험들에 대한 정렬방법은 나중에 생각하고, 어떤 형태로 저장하는가이다.
        /// 간단하게 '상황'과 '환경'이라고 했는데, 도대체 뭘까?
        /// 환경은 단순하게 그 순간의 공간정보라고 볼 수 있을 것이다.
        /// 인지하고 있는 주위 환경타일과 필드오브젝트를 그대로 넣으면 되는 것인데,
        /// 문제는 어느정도의 범위까지 정해서 공간정보를 저장하는가이다.
        /// 뭐 일단 인식중인 맵을 전부 기억할까? 나중에 개선하면 되겠지.
        /// 그럼 다른 문제 '상황'이라는 건 뭘까?
        /// 상황이라는 것은 연속된 시간 속에서 인지된 변화를 함축하는 것?
        /// 아니면 단순하게 공간정보에 인지된 필드오브젝트들의 행동을 추가한것?
        /// 단순히 그 순간의 필드오브젝트들의 행동을 추가해서는 '상황'이라고 표현 할 수도 없고,
        /// 그걸로는 그다지 정보를 얻을 수도 없다.
        /// 상황이란 이런 순간이 되기까지의 '과정'이 들어있어야 한다.
        /// 거기에 더해 어떤 '일/행동/사건'이 완성되거나 되어가는 과정 전체를 설명하는 것이다.
        /// 즉, 여기서 음식를 발견/ 구한 순간의 상황을 설명하자면,
        /// '목적'에 따라(없을 수 도 있나?) '이동' 중에 '음식'를 '발견'해서 '음식'를
        /// '얻기'위해 '이동'해서 음식를 '획득'한 것이다.
        /// 기억에는 어떤 '목적/동기'로 '이동'중에 '어디서' '음식'를 '발견'하였다.를
        /// 시간순으로 나열 하면 되는 것이다.
        /// 그래 지금까지 해왔던 시간종속염소그래프와 비슷하다. 중요한건 거기에 '공간/환경'의 정보를
        /// 같이 넣어야 한다는 것이다.

        /// 또 다른 문제는 공간 정보 = 2차원 정보인데, 아직 공간을 인지하는 방식을 정하지 않았다.
        /// 현재 게임세상에서 생물은 어떻게 필들/공간과 그 필드를 분할하는 환경을 인식할까?
        /// 솔직히 필드의 분할된 환경들과 시야 사이에서 생긴 다각형들을 단순화/기호화 시켜서
        /// 기억하는 방식이 실제 인간의 방식과 닮았다고 생각된다.
        /// 당장에 그렇게 하기에는 그런 알고리즘을 만드는 시간과 그걸 만들었을 때,
        /// 실제로 충분히 시간과 공간이 되는지도 알 수가 없다는 것이다.
        /// 그래서 일단 생각난 다른 방법은 게임 세상의 특성을 살린 객관적인/절대적인 좌표계를
        /// 이용하는 방법이다.
        /// 기억에는 공간의 전체적인 크기(네모든 동그라미든)와 중심 위치만 입력해 놓고,
        /// 필드오브젝트도 필드의 절대좌표를 그대로 넣어 놓는다.
        /// 나중에 그 기억/경험이 필요해서 떠올리게 되면 그 순간 단 하나만 존재하는 필드의
        /// 환경에 오브젝트들을 위치시키고 상상을 시키는 것이다.

        /// 여기서 생각해봐야 할 것은 실제로 기억/경험이 어떻게 사용되는가이다.
        /// 기억/경험에서 장소/공간을 같이 기억하는 이유는 바로 '음식'를 찾기 위해서이다.
        /// 머릿속에 '음식'가 연상된다면 자연스럽게 거기에 연관된 것들이 떠오를 것이다.
        /// 여러 기억/경험 중에서 순서대로든 아니면 다른 방법이든 기억/경험을 상상하게 될텐데,
        /// 거기서 음식를 얻은 장소와 공간을 상상속에서(실제로는 필드자체를) 보는 것은 
        /// 어렵지 않고 문제도 없다.
        /// 다만 이렇게 '음식'와 '장소/공간/상황'을 연결하려는 이유는 '특정 상황/장소'에서
        /// '특정 음식'를 얻을 수 있다는 '지식'을 학습시키기 위해서이다.
        /// 여기서 말하는 '지식'은 반복된 경험/기억을 통해 학습된 하나의 명제와도 같다.
        /// 분명 '특정 음식(같은 종류의 같은 특징의 음식)'를 여러 '장소'에서 획득하면
        /// 그 '특정 장소'와 '특정 상황'의 공통점이 있을 것이다.
        /// 거기서 '특정 음식'이 과 '특정 상황/장소'에 대한 연결된 '정보'를 만들어 내야한다.
        /// 그렇다면 그 '정보'의 형태는 어떻고? 어떻게 연결되는가?
        /// 일단 '기억/경험'을 하는 모델을 만들어놓고 생각해 볼까?

        Think1();

        enterFieldObjects.Clear();
        exitFieldObjects.Clear();
    }

    private void Think1()
    {
        YTime previousTime = null;
        YTime currentTime = new YTime(Time.time);

        if (timeline.Count != 0)
        {
            previousTime = timeline.Last.Value;
        }

        timeline.AddLast(currentTime);

        Judge_EvaluateRecognizedObjects();

        UpdateRecognitionOfField();

        /// 현재까지의 자신의 행동과 상태, 주변 정보들을 종합해서
        /// 현재 상황/사건을 구축하고, 그 다음 행동을 결정하자.

        /// 변화를 감지
        /// 좀 더 정확하게는 이전 순간에 자신이 하려고 했던 행동과 현재 상태를 비교하고,
        /// 연속되지 않는 변화나 예상 밖의 변화등을 감지하고, 상황에 기록 사건을 구성하고 행동한다.

        SelfStateData currentData;
        currentData.sight = selfBody.Sight;
        currentData.position = selfBody.Position;
        currentData.direction = selfBody.Direction;
        currentData.moveSpeed = selfBody.MoveSpeed;
        currentData.actionState = selfBody.ActionState;

        Ye_SelfState currentSelfState = new Ye_SelfState(currentTime, currentData);
        Ye_SelfState previousState = null;
        if (selfStates.Count != 0)
        {
            previousState = selfStates.Last.Value;
        }

        // 예상 상태와 비교
        if (currentData != expectedData)
        {

        }

        // 임시 행동 결정 => 원래는 자신의 상태와 상황을 보고 의사/행동 결정을 실시
        // 블랙박스1 : 어떤 과정을 거쳐서 먹기로 마음을 먹음. => 만약 필요하다면 따로 프레임을 나누어서 상념에 기록.
        if (hugerPoint < 50)
        {
            // 블랙박스2 : 어떤 과정을 거쳐서 먹기로 하기위해 eat개념을 찾음.
            Gaenyeom gaenyeom_eat = gaenyeoms[Gaenyeom.EGaenyeomTypePreset.Eat];
        }

        // 다음 순간의 행동/상황/변화 등의 예상

    }

    void Create_OrganizeEvent()
    {

    }

    /// <summary>
    /// 인지 중인 객체들에 대한 판단/평가. +의문
    /// 단순히 객체가 현재 하는 행동에 대한 판단도 포함되지만,
    /// 그 객체가 '왜' 그런 행동을 하는지, 앞으로 어떤 행동을 할지의 '예상'등도 포함된다.
    /// 하지만 어떤 객체에 대한 깊은 판단/평가가 여기서 이루어 지는게 맞는지?
    /// 또 그게 인지중인 물체에 대해 전반적으로 일어나는게 맞는지?
    /// 분명 어떤 물체에 대한 깊은 판/평은 이루어 진다.
    /// 다만 그것을 하는 과정 전체가 '시간이 걸리는' 실제의 '사고/생각'이고,
    /// 이걸 어느 부분에서 어떤 식으로 해서 상념에 연결시킬지는 생각을 해봐야한다.
    /// </summary>
    void Judge_EvaluateRecognizedObjects()
    {

    }

    void UpdateRecognitionOfField()
    {
        foreach (var fe in enterFieldEnvironments)
        {
            recognizedFieldEnvironments.AddLast(fe);
        }

        foreach (var fe in exitFieldEnvironments)
        {
            // O(n) -> 자료구조 수정바람.
            recognizedFieldEnvironments.Remove(fe);
        }
    }

    void UpdateSelfState()
    {
        // 이건 캐릭터 자신이 스스로 생각해서 행동의 변화를 결정하고 내려야하는것 아닌가?
        YTime currentTime = timeline.Last.Value;
        YTime previousTime = timeline.Last.Previous.Value;

        SelfStateData selfData;
        selfData.sight = selfBody.Sight;
        selfData.position = selfBody.Position;
        selfData.direction = selfBody.Direction;
        selfData.moveSpeed = selfBody.MoveSpeed;
        selfData.actionState = selfBody.ActionState;

        Ye_SelfState currentSelfState = new Ye_SelfState(currentTime, selfData);

        // 변화를 감지
        Ye_SelfState previousState = selfStates.Last.Value;
    }

    private void OnTriggerEnter2D(Collider2D collision)
    {
        if (collision.tag == "FieldObject")
        {
            var fieldObject = collision.GetComponent<FieldObject>();

            if (fieldObject == null)
            {
                return;
            }

            enterFieldObjects.Add(fieldObject);
        }
        else if (collision.tag == "FieldEnvironment")
        {
            var fieldEnvironment = collision.GetComponent<FieldEnvironment>();

            if (fieldEnvironment == null)
            {
                return;
            }

            enterFieldEnvironments.Add(fieldEnvironment);
        }
    }

    private void OnTriggerExit2D(Collider2D collision)
    {
        if (collision.tag == "FieldObject")
        {
            var fieldObject = collision.GetComponent<FieldObject>();

            if (fieldObject == null)
            {
                return;
            }

            exitFieldObjects.Add(fieldObject);
        }
        else if (collision.tag == "FieldEnvironment")
        {
            var fieldEnvironment = collision.GetComponent<FieldEnvironment>();

            if (fieldEnvironment == null)
            {
                return;
            }

            exitFieldEnvironments.Add(fieldEnvironment);
        }
    }
}
